{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f29c2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/boston.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d384668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee73fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_train = df.iloc[:, :13].values\n",
    "# X_train = torch.tensor(X_train)\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "\n",
    "y_train = df.iloc[:, -1].values\n",
    "y_train = torch.FloatTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "14aae888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=13, out_features=100, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim.adam import Adam\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(13, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 1),\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c5c196c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 0.weight\n",
      "Shape: torch.Size([100, 13])\n",
      "Values: Parameter containing:\n",
      "tensor([[-0.0251,  0.0909,  0.2697,  ..., -0.1142,  0.2060,  0.1440],\n",
      "        [ 0.2474,  0.1060, -0.2062,  ...,  0.0548,  0.2571, -0.1074],\n",
      "        [-0.1489, -0.0154, -0.2140,  ..., -0.1717,  0.1545, -0.0724],\n",
      "        ...,\n",
      "        [ 0.1052,  0.0052, -0.2471,  ...,  0.2655,  0.2354, -0.0558],\n",
      "        [-0.1893,  0.2746,  0.0006,  ..., -0.2732,  0.1313, -0.2499],\n",
      "        [ 0.0472,  0.0154,  0.2320,  ...,  0.2564, -0.2600, -0.1473]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Name: 0.bias\n",
      "Shape: torch.Size([100])\n",
      "Values: Parameter containing:\n",
      "tensor([ 0.2720, -0.0673,  0.0906, -0.0750,  0.2453,  0.2454, -0.0454, -0.0633,\n",
      "        -0.0148, -0.0405, -0.1227,  0.1558, -0.2725, -0.0855,  0.2045,  0.2120,\n",
      "        -0.0059,  0.0188,  0.0703, -0.1354,  0.0322,  0.0722,  0.1120, -0.0763,\n",
      "        -0.2312,  0.2686,  0.1953, -0.1371, -0.2122,  0.2718, -0.0318, -0.0680,\n",
      "         0.2362, -0.1190,  0.2724, -0.0238, -0.2608, -0.2732, -0.2604,  0.2302,\n",
      "         0.2388,  0.1243,  0.1785, -0.2631,  0.0513,  0.1303,  0.0896,  0.1323,\n",
      "        -0.0039, -0.0181, -0.2656,  0.2460, -0.1361,  0.1151,  0.1910,  0.1579,\n",
      "         0.1929,  0.1070,  0.1952,  0.2295,  0.0717, -0.2509,  0.2721, -0.1934,\n",
      "        -0.2331,  0.1736, -0.2281,  0.2124, -0.2452,  0.0913, -0.0310,  0.0339,\n",
      "        -0.1455,  0.2358,  0.1243,  0.1399, -0.0019,  0.0219,  0.2269, -0.2422,\n",
      "        -0.1733, -0.0569, -0.1409, -0.1644,  0.2708, -0.2231, -0.2763, -0.1292,\n",
      "        -0.1610, -0.1009,  0.1298, -0.0251, -0.2475,  0.1942, -0.1815,  0.1589,\n",
      "        -0.2201, -0.1598,  0.0363,  0.1440], requires_grad=True)\n",
      "\n",
      "Name: 2.weight\n",
      "Shape: torch.Size([50, 100])\n",
      "Values: Parameter containing:\n",
      "tensor([[-0.0197,  0.0629,  0.0677,  ...,  0.0470,  0.0681,  0.0316],\n",
      "        [-0.0896,  0.0522,  0.0459,  ..., -0.0069,  0.0717,  0.0748],\n",
      "        [ 0.0959,  0.0013,  0.0810,  ..., -0.0691, -0.0127, -0.0637],\n",
      "        ...,\n",
      "        [-0.0399, -0.0643, -0.0960,  ..., -0.0744,  0.0687, -0.0301],\n",
      "        [-0.0373,  0.0256,  0.0570,  ..., -0.0823, -0.0112, -0.0309],\n",
      "        [ 0.0615, -0.0651, -0.0855,  ...,  0.0858,  0.0795,  0.0808]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Name: 2.bias\n",
      "Shape: torch.Size([50])\n",
      "Values: Parameter containing:\n",
      "tensor([-0.0010,  0.0444,  0.0832,  0.0171, -0.0511, -0.0193, -0.0726,  0.0263,\n",
      "        -0.0581, -0.0284, -0.0957, -0.0537, -0.0553, -0.0072, -0.0060, -0.0303,\n",
      "         0.0229, -0.0707, -0.0074, -0.0536, -0.0446,  0.0520, -0.0555,  0.0926,\n",
      "         0.0387, -0.0709,  0.0025,  0.0279, -0.0814,  0.0366,  0.0729,  0.0698,\n",
      "         0.0234,  0.0964, -0.0221,  0.0518, -0.0847,  0.0412,  0.0517, -0.0776,\n",
      "         0.0190, -0.0502,  0.0109,  0.0666, -0.0350,  0.0462,  0.0953, -0.0987,\n",
      "        -0.0422, -0.0460], requires_grad=True)\n",
      "\n",
      "Name: 4.weight\n",
      "Shape: torch.Size([1, 50])\n",
      "Values: Parameter containing:\n",
      "tensor([[ 0.0767, -0.0088,  0.1398, -0.0939,  0.0149,  0.0248, -0.0729, -0.0467,\n",
      "          0.1259, -0.0807,  0.0664,  0.0546, -0.0950, -0.0359,  0.0066,  0.0299,\n",
      "         -0.1195,  0.1372,  0.0445, -0.1289,  0.0233, -0.1357, -0.1189,  0.0607,\n",
      "          0.1171, -0.1402, -0.0049,  0.0598,  0.1099, -0.0564, -0.1189,  0.0853,\n",
      "          0.0797,  0.0296, -0.0984,  0.0760,  0.0188,  0.0536,  0.0519, -0.0297,\n",
      "          0.0606,  0.0752,  0.0595, -0.0800, -0.0542,  0.0694,  0.0414,  0.0799,\n",
      "          0.0067, -0.0175]], requires_grad=True)\n",
      "\n",
      "Name: 4.bias\n",
      "Shape: torch.Size([1])\n",
      "Values: Parameter containing:\n",
      "tensor([-0.0486], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Name: {name}\")\n",
    "    print(f\"Shape: {param.shape}\")\n",
    "    print(f\"Values: {param}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "beb14763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  85.87886810302734\n",
      "loss:  75.40967559814453\n",
      "loss:  67.30426788330078\n",
      "loss:  71.0103988647461\n",
      "loss:  68.38074493408203\n",
      "loss:  70.65353393554688\n",
      "loss:  67.3873519897461\n",
      "loss:  64.38365173339844\n",
      "loss:  64.6181411743164\n",
      "loss:  62.95616149902344\n",
      "loss:  62.18092346191406\n",
      "loss:  63.564640045166016\n",
      "loss:  63.151432037353516\n",
      "loss:  62.185428619384766\n",
      "loss:  62.37262725830078\n",
      "loss:  61.5926628112793\n",
      "loss:  60.23634338378906\n",
      "loss:  60.15493392944336\n",
      "loss:  60.1583366394043\n",
      "loss:  59.6104736328125\n",
      "loss:  59.75189208984375\n",
      "loss:  59.909385681152344\n",
      "loss:  59.26201629638672\n",
      "loss:  58.839969635009766\n",
      "loss:  58.737186431884766\n",
      "loss:  58.20669174194336\n",
      "loss:  57.84830856323242\n",
      "loss:  57.98489761352539\n",
      "loss:  57.850982666015625\n",
      "loss:  57.6306266784668\n",
      "loss:  57.600059509277344\n",
      "loss:  57.30930709838867\n",
      "loss:  56.93014144897461\n",
      "loss:  56.810325622558594\n",
      "loss:  56.62168884277344\n",
      "loss:  56.40744400024414\n",
      "loss:  56.36968994140625\n",
      "loss:  56.19646072387695\n",
      "loss:  55.93058776855469\n",
      "loss:  55.76243209838867\n",
      "loss:  55.50497055053711\n",
      "loss:  55.2668571472168\n",
      "loss:  55.14923095703125\n",
      "loss:  54.9608154296875\n",
      "loss:  54.784446716308594\n",
      "loss:  54.626930236816406\n",
      "loss:  54.37631607055664\n",
      "loss:  54.16329574584961\n",
      "loss:  53.9659309387207\n",
      "loss:  53.743412017822266\n",
      "loss:  53.57903289794922\n",
      "loss:  53.38571548461914\n",
      "loss:  53.17271041870117\n",
      "loss:  52.97637176513672\n",
      "loss:  52.742733001708984\n",
      "loss:  52.53765869140625\n",
      "loss:  52.34117889404297\n",
      "loss:  52.13288497924805\n",
      "loss:  51.940086364746094\n",
      "loss:  51.71620559692383\n",
      "loss:  51.49418640136719\n",
      "loss:  51.26951599121094\n",
      "loss:  51.04358673095703\n",
      "loss:  50.83396911621094\n",
      "loss:  50.6099967956543\n",
      "loss:  50.3857421875\n",
      "loss:  50.15129470825195\n",
      "loss:  49.917991638183594\n",
      "loss:  49.687808990478516\n",
      "loss:  49.451087951660156\n",
      "loss:  49.2169075012207\n",
      "loss:  48.97147750854492\n",
      "loss:  48.72910690307617\n",
      "loss:  48.48086166381836\n",
      "loss:  48.236976623535156\n",
      "loss:  47.986305236816406\n",
      "loss:  47.73006057739258\n",
      "loss:  47.47494888305664\n",
      "loss:  47.21635437011719\n",
      "loss:  46.961036682128906\n",
      "loss:  46.702388763427734\n",
      "loss:  46.44282150268555\n",
      "loss:  46.18028259277344\n",
      "loss:  45.921470642089844\n",
      "loss:  45.65745162963867\n",
      "loss:  45.392398834228516\n",
      "loss:  45.122474670410156\n",
      "loss:  44.85377883911133\n",
      "loss:  44.582889556884766\n",
      "loss:  44.30965042114258\n",
      "loss:  44.030887603759766\n",
      "loss:  43.74995422363281\n",
      "loss:  43.47044372558594\n",
      "loss:  43.18937683105469\n",
      "loss:  42.90665817260742\n",
      "loss:  42.623130798339844\n",
      "loss:  42.33814239501953\n",
      "loss:  42.05225372314453\n",
      "loss:  41.76673126220703\n",
      "loss:  41.48143768310547\n",
      "loss:  41.19538497924805\n",
      "loss:  40.91102600097656\n",
      "loss:  40.62569046020508\n",
      "loss:  40.34092712402344\n",
      "loss:  40.055946350097656\n",
      "loss:  39.76957702636719\n",
      "loss:  39.4843864440918\n",
      "loss:  39.199684143066406\n",
      "loss:  38.914215087890625\n",
      "loss:  38.62864303588867\n",
      "loss:  38.34402847290039\n",
      "loss:  38.06117630004883\n",
      "loss:  37.78022003173828\n",
      "loss:  37.499298095703125\n",
      "loss:  37.2187385559082\n",
      "loss:  36.93867874145508\n",
      "loss:  36.659481048583984\n",
      "loss:  36.38247299194336\n",
      "loss:  36.107425689697266\n",
      "loss:  35.83367919921875\n",
      "loss:  35.561710357666016\n",
      "loss:  35.29273986816406\n",
      "loss:  35.02869415283203\n",
      "loss:  34.76982116699219\n",
      "loss:  34.514644622802734\n",
      "loss:  34.265113830566406\n",
      "loss:  34.020057678222656\n",
      "loss:  33.78403854370117\n",
      "loss:  33.56843948364258\n",
      "loss:  33.39510726928711\n",
      "loss:  33.29227828979492\n",
      "loss:  33.224422454833984\n",
      "loss:  33.07933807373047\n",
      "loss:  32.70115661621094\n",
      "loss:  32.2382698059082\n",
      "loss:  31.943246841430664\n",
      "loss:  31.863910675048828\n",
      "loss:  31.84868812561035\n",
      "loss:  31.71932601928711\n",
      "loss:  31.416358947753906\n",
      "loss:  31.051694869995117\n",
      "loss:  30.79107666015625\n",
      "loss:  30.68260955810547\n",
      "loss:  30.64830207824707\n",
      "loss:  30.58953094482422\n",
      "loss:  30.43233871459961\n",
      "loss:  30.187517166137695\n",
      "loss:  29.907400131225586\n",
      "loss:  29.674779891967773\n",
      "loss:  29.520122528076172\n",
      "loss:  29.427410125732422\n",
      "loss:  29.36825942993164\n",
      "loss:  29.326101303100586\n",
      "loss:  29.29587745666504\n",
      "loss:  29.243207931518555\n",
      "loss:  29.108081817626953\n",
      "loss:  28.857845306396484\n",
      "loss:  28.542863845825195\n",
      "loss:  28.24875259399414\n",
      "loss:  28.046833038330078\n",
      "loss:  27.945650100708008\n",
      "loss:  27.902299880981445\n",
      "loss:  27.845788955688477\n",
      "loss:  27.746292114257812\n",
      "loss:  27.58639907836914\n",
      "loss:  27.408130645751953\n",
      "loss:  27.255090713500977\n",
      "loss:  27.14675521850586\n",
      "loss:  27.062780380249023\n",
      "loss:  26.98283576965332\n",
      "loss:  26.904394149780273\n",
      "loss:  26.82662010192871\n",
      "loss:  26.74894905090332\n",
      "loss:  26.677204132080078\n",
      "loss:  26.59707260131836\n",
      "loss:  26.512920379638672\n",
      "loss:  26.407093048095703\n",
      "loss:  26.277145385742188\n",
      "loss:  26.102153778076172\n",
      "loss:  25.923431396484375\n",
      "loss:  25.763687133789062\n",
      "loss:  25.640316009521484\n",
      "loss:  25.565017700195312\n",
      "loss:  25.525650024414062\n",
      "loss:  25.506786346435547\n",
      "loss:  25.496746063232422\n",
      "loss:  25.505990982055664\n",
      "loss:  25.508089065551758\n",
      "loss:  25.510648727416992\n",
      "loss:  25.445770263671875\n",
      "loss:  25.326007843017578\n",
      "loss:  25.123077392578125\n",
      "loss:  24.90106201171875\n",
      "loss:  24.70608139038086\n",
      "loss:  24.577238082885742\n",
      "loss:  24.507823944091797\n",
      "loss:  24.47572898864746\n",
      "loss:  24.46023178100586\n",
      "loss:  24.450725555419922\n",
      "loss:  24.447574615478516\n"
     ]
    }
   ],
   "source": [
    "optim = Adam(model.parameters(), lr = 0.001)\n",
    "epochs = 200\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    optim.zero_grad()\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train.view(-1, 1))\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    print('loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "32545583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.0665,  0.1112,  0.2402,  ..., -0.1594,  0.1999,  0.0296],\n",
       "                      [ 0.3573, -0.0038, -0.2997,  ..., -0.1258,  0.2470, -0.3105],\n",
       "                      [-0.2024, -0.0163, -0.2300,  ..., -0.2167,  0.1550, -0.2023],\n",
       "                      ...,\n",
       "                      [-0.0497,  0.0280, -0.1838,  ...,  0.3152,  0.2258,  0.0323],\n",
       "                      [ 0.0338,  0.3144, -0.1976,  ..., -0.4692,  0.1221, -0.4443],\n",
       "                      [ 0.0386,  0.0154,  0.2246,  ...,  0.2489, -0.2679, -0.1547]])),\n",
       "             ('0.bias',\n",
       "              tensor([ 2.9799e-01, -2.9983e-02,  1.3776e-01, -7.5007e-02,  2.3105e-01,\n",
       "                       1.8165e-01,  6.6497e-03, -2.3162e-02, -1.4793e-02, -5.9216e-05,\n",
       "                      -1.1710e-01,  1.6962e-01, -2.5140e-01, -1.2355e-01,  2.3831e-01,\n",
       "                       2.4879e-01,  5.4847e-02,  5.2901e-02,  1.0145e-01, -1.8847e-01,\n",
       "                       3.2232e-02,  7.2247e-02,  5.6890e-02, -1.4399e-01, -2.7794e-01,\n",
       "                       2.6859e-01,  2.4211e-01, -2.3261e-02, -2.1439e-01,  2.6163e-01,\n",
       "                       1.9004e-03, -6.0485e-02,  2.6535e-01, -1.6068e-01,  2.7238e-01,\n",
       "                       3.4183e-02, -2.3897e-01, -2.3674e-01, -2.6044e-01,  2.4973e-01,\n",
       "                       2.2906e-01,  1.0992e-01,  1.7851e-01, -2.6305e-01,  1.1006e-01,\n",
       "                       1.7696e-01,  9.9404e-02,  8.9095e-02, -3.0341e-02, -1.2814e-02,\n",
       "                      -2.3731e-01,  2.4599e-01, -9.1796e-02,  1.1344e-01,  2.6760e-01,\n",
       "                       1.9947e-01,  2.1552e-01,  1.2021e-01,  1.9518e-01,  2.2948e-01,\n",
       "                       5.5060e-02, -2.6460e-01,  2.9985e-01, -1.6089e-01, -1.8955e-01,\n",
       "                       2.1889e-01, -2.2808e-01,  2.3768e-01, -2.4523e-01,  8.7587e-02,\n",
       "                      -3.0986e-02,  1.0381e-01, -1.5388e-01,  2.8087e-01,  7.2836e-02,\n",
       "                       9.8416e-02, -2.7472e-03, -1.5941e-02,  2.2689e-01, -3.2207e-01,\n",
       "                      -1.4279e-01, -5.6911e-02, -1.7196e-01, -1.6441e-01,  3.3709e-01,\n",
       "                      -3.0678e-01, -2.7626e-01, -1.3811e-01, -1.2247e-01, -1.4511e-01,\n",
       "                       1.8073e-01,  8.0258e-03, -2.9632e-01,  2.6083e-01, -2.3193e-01,\n",
       "                       1.5889e-01, -2.7914e-01, -1.7817e-01,  4.2776e-02,  1.3649e-01])),\n",
       "             ('2.weight',\n",
       "              tensor([[-0.0211,  0.0948,  0.0747,  ...,  0.0517,  0.1600,  0.0395],\n",
       "                      [-0.0967,  0.0451,  0.0384,  ..., -0.0204,  0.0584,  0.0670],\n",
       "                      [ 0.0904,  0.0407,  0.0847,  ..., -0.0523,  0.0822, -0.0559],\n",
       "                      ...,\n",
       "                      [-0.0466, -0.0699, -0.1028,  ..., -0.0744,  0.0687, -0.0374],\n",
       "                      [-0.0433,  0.0256,  0.0510,  ..., -0.0823, -0.0112, -0.0369],\n",
       "                      [ 0.0546, -0.0720, -0.0924,  ...,  0.0789,  0.0724,  0.0808]])),\n",
       "             ('2.bias',\n",
       "              tensor([ 0.0431,  0.0345,  0.1241, -0.0268, -0.0048,  0.0082, -0.1095,  0.0263,\n",
       "                      -0.0671, -0.0284, -0.0541, -0.0605, -0.0989, -0.0072, -0.0148,  0.0200,\n",
       "                      -0.0168, -0.0394, -0.0178, -0.0954, -0.0532,  0.0112, -0.0636,  0.0926,\n",
       "                       0.0809, -0.0792,  0.0725,  0.0732, -0.0635,  0.0285,  0.0729,  0.1106,\n",
       "                       0.0678,  0.0865, -0.0221,  0.0518, -0.0411,  0.0412,  0.0966, -0.1156,\n",
       "                       0.0190, -0.0088,  0.0572,  0.0666, -0.0538,  0.0874,  0.0953, -0.1056,\n",
       "                      -0.0482, -0.0528])),\n",
       "             ('4.weight',\n",
       "              tensor([[ 0.0968,  0.0019,  0.2107, -0.1125,  0.0265,  0.0180, -0.0777, -0.0467,\n",
       "                        0.1151, -0.0807,  0.0702,  0.0472, -0.1380, -0.0359, -0.0041,  0.0899,\n",
       "                       -0.1290,  0.1441,  0.0323, -0.2064,  0.0131, -0.1887, -0.1394,  0.0607,\n",
       "                        0.1254, -0.1323,  0.0381,  0.0902,  0.1027, -0.0489, -0.1189,  0.1243,\n",
       "                        0.1118,  0.0200, -0.0984,  0.0760,  0.0260,  0.0536,  0.0976, -0.0423,\n",
       "                        0.0606,  0.0784,  0.0897, -0.0800, -0.0499,  0.0699,  0.0414,  0.0718,\n",
       "                        0.0007, -0.0106]])),\n",
       "             ('4.bias', tensor([-0.0068]))])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f479ece6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e6df5a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0320>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806C67B60>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0320>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806C67B60>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0320>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806C67B60>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0320>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806C67B60>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0320>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806C67B60>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0320>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806C67B60>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0320>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806C67B60>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806A766C0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0320>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806C67BB0>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806C67BB0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806C67B60>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0320>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0320>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0320>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806C67B60>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806567D40>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0320>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0550>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278064355E0>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065FB750>\n",
      "loss:  <built-in method item of Tensor object at 0x00000278065EF480>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806697110>\n",
      "loss:  <built-in method item of Tensor object at 0x0000027806AC0550>\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "optim = Adam(model.parameters(), lr= 0.001)\n",
    "epoch = 200\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    optim.zero_grad()\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train.view(-1, 1))\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    print('loss: ', loss.item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270fb39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
